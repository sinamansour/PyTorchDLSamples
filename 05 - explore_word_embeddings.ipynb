{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "8646ffac-68f8-4d60-8510-55cc889e030b",
      "metadata": {
        "id": "8646ffac-68f8-4d60-8510-55cc889e030b"
      },
      "source": [
        "### ---SINA---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c61b007d-b6f2-4e44-ad9d-b17a2eb422fe",
      "metadata": {
        "id": "c61b007d-b6f2-4e44-ad9d-b17a2eb422fe"
      },
      "source": [
        "## Imports "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "49a7e39c-95dc-4811-b325-36243a4e6694",
      "metadata": {
        "id": "49a7e39c-95dc-4811-b325-36243a4e6694"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import json\n",
        "import re\n",
        "import math\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data.dataloader import default_collate"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9adecc40-4a13-42b3-b2df-4475909a8532",
      "metadata": {
        "id": "9adecc40-4a13-42b3-b2df-4475909a8532"
      },
      "source": [
        "## Some useful constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "20d92b82-4267-4cd7-8a5f-67d7e0e0faad",
      "metadata": {
        "id": "20d92b82-4267-4cd7-8a5f-67d7e0e0faad"
      },
      "outputs": [],
      "source": [
        "EMB_SIZE = 300\n",
        "PAD_TOKEN = '<PAD>'\n",
        "UNK_TOKEN = '<UNK>'\n",
        "TRAIN_BATCH_SIZE = 32\n",
        "TEST_EVAL_BATCH_SIZE = 32"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2697fea-9c12-4ab7-bb4f-68881db3b471",
      "metadata": {
        "id": "c2697fea-9c12-4ab7-bb4f-68881db3b471"
      },
      "source": [
        "## Load the data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "160b7647-70ce-4c3f-a1e9-9311eb68c637",
      "metadata": {
        "id": "160b7647-70ce-4c3f-a1e9-9311eb68c637"
      },
      "source": [
        "This data is based on\n",
        "<a href=\"http://www.cs.cornell.edu/people/pabo/movie-review-data/\">this link</a>\n",
        "and contains movie reviews sentiment-analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "7131e553-3b17-4cef-b940-7b79f0b45a37",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7131e553-3b17-4cef-b940-7b79f0b45a37",
        "outputId": "ee4cdfb8-f413-464b-a88b-1e0fe59ec1ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train lenght is: 8000\n",
            "eval lenght is: 2000\n",
            "test lenght is: 662\n"
          ]
        }
      ],
      "source": [
        "with open('./dataset.json') as f:\n",
        "    all_dataset = json.load(f)\n",
        "    \n",
        "for section in all_dataset.keys():\n",
        "    l = len(all_dataset[section])\n",
        "    print(f\"{section} lenght is: {l}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "226ae1ee-8c58-4701-99ef-344a0a4c6d97",
      "metadata": {
        "id": "226ae1ee-8c58-4701-99ef-344a0a4c6d97"
      },
      "source": [
        "## Download and extract the embeddings"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "712b9324",
      "metadata": {},
      "source": [
        "In this project we will use pretrained GloVe model.\n",
        "\n",
        "using following code you can mount your google drive so you don't need to DL it again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "KYCwVmQ4NV9R",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYCwVmQ4NV9R",
        "outputId": "a018587e-2e5e-46a5-ae6d-c8c31071d41d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Archive:  /content/drive/My Drive/GloveEmbeddings/glove.6B.zip\n",
            "  inflating: ./glove/glove.6B.50d.txt  \n",
            "  inflating: ./glove/glove.6B.100d.txt  \n",
            "  inflating: ./glove/glove.6B.200d.txt  \n",
            "  inflating: ./glove/glove.6B.300d.txt  \n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# !mkdir '/content/drive/My Drive/GloveEmbeddings'\n",
        "# !cp /content/glove.6B.zip '/content/drive/My Drive/GloveEmbeddings/'\n",
        "!unzip '/content/drive/My Drive/GloveEmbeddings/glove.6B.zip' -d \"./glove/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "de951110-ed5c-4983-84f9-7986a864b870",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "de951110-ed5c-4983-84f9-7986a864b870",
        "outputId": "fdbbcf7b-e1ae-44fa-b0e3-39668b857a85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-01-02 20:20:29--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2023-01-02 20:20:29--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.01MB/s    in 2m 39s  \n",
            "\n",
            "2023-01-02 20:23:09 (5.17 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://nlp.stanford.edu/data/glove.6B.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2d20001-b797-4fbd-ae78-b0e53c5456f0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2d20001-b797-4fbd-ae78-b0e53c5456f0",
        "outputId": "201589d6-02d8-43b3-bfd3-ff1ca5dfd0ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  ./glove.6B.zip\n",
            "  inflating: ./glove/glove.6B.50d.txt  \n",
            "  inflating: ./glove/glove.6B.100d.txt  \n",
            "  inflating: ./glove/glove.6B.200d.txt  \n",
            "  inflating: ./glove/glove.6B.300d.txt  \n"
          ]
        }
      ],
      "source": [
        "!unzip ./glove.6B.zip -d \"./glove/\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "695db153-b2e6-4650-a0f1-f46e62995061",
      "metadata": {
        "id": "695db153-b2e6-4650-a0f1-f46e62995061"
      },
      "source": [
        "## Create embedding matrix and useful functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "4d14e34c-032d-4ba0-b55c-e3abb84194a7",
      "metadata": {
        "id": "4d14e34c-032d-4ba0-b55c-e3abb84194a7"
      },
      "outputs": [],
      "source": [
        "word_list = []\n",
        "emb_list = []\n",
        "with open(f'./glove/glove.6B.{EMB_SIZE}d.txt','r') as f:\n",
        "    for line in f.read().strip().split('\\n'):\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        emb = values[1:]\n",
        "        word_list.append(word)\n",
        "        emb_list.append(emb)\n",
        "        \n",
        "emb_matrix = np.array(emb_list, 'float32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "acf153cb-e1f6-4e51-8e4d-c3380f145a39",
      "metadata": {
        "id": "acf153cb-e1f6-4e51-8e4d-c3380f145a39"
      },
      "outputs": [],
      "source": [
        "# We initialize <UNK> token as an average of all embedings\n",
        "unk_emb = np.mean(emb_matrix, axis=0, keepdims=True)\n",
        "word_list.append(UNK_TOKEN)\n",
        "emb_matrix = np.vstack((emb_matrix, unk_emb))\n",
        "\n",
        "# We initialize <PAD> token as zeroes\n",
        "pad_emb = np.zeros((1, EMB_SIZE))\n",
        "word_list.append(PAD_TOKEN)\n",
        "emb_matrix = np.vstack((emb_matrix, pad_emb))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "28be1a5a-1f6a-4185-9479-ff687013baf8",
      "metadata": {
        "id": "28be1a5a-1f6a-4185-9479-ff687013baf8"
      },
      "outputs": [],
      "source": [
        "reverse_map = {word: id for (id, word) in enumerate(word_list)}\n",
        "\n",
        "def word_to_ids(word: str) -> list:\n",
        "    word = word.strip()\n",
        "    if word == \"\":\n",
        "        return []\n",
        "    if word in reverse_map:\n",
        "        return [reverse_map[word]]\n",
        "    elif word[-3:] in [\"n't\", \"'re\"]:\n",
        "        return word_to_ids(word[:-3]) + word_to_ids(word[-3:])\n",
        "    elif word[-2:] in [\"'s\", \"'d\", \"'m\"]:\n",
        "        return word_to_ids(word[:-2]) + word_to_ids(word[-2:])\n",
        "    else:\n",
        "        word = word.replace(\"'\", \"\")\n",
        "        if word in reverse_map:\n",
        "            return [reverse_map[word]]\n",
        "    return [reverse_map[UNK_TOKEN]]\n",
        "    \n",
        "def id_to_word(id: int) -> str:\n",
        "    return word_list[id]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11c3f21c-b625-4461-b307-9dcfb14bd163",
      "metadata": {
        "id": "11c3f21c-b625-4461-b307-9dcfb14bd163"
      },
      "source": [
        "## Tokenizer and sentence useful tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "27aeef5d-8ef8-4bc9-8514-9447dab88e3c",
      "metadata": {
        "id": "27aeef5d-8ef8-4bc9-8514-9447dab88e3c"
      },
      "outputs": [],
      "source": [
        "def tokenizer(sentence: str) -> list:\n",
        "    sentence = sentence.strip()\n",
        "    return re.split(\"[ -]+\", sentence)\n",
        "\n",
        "def sentence_to_ids(sentence: str) -> list:\n",
        "    return sum(map(word_to_ids, tokenizer(sentence)), [])\n",
        "\n",
        "def ids_to_sentence(ids: list) -> list:\n",
        "    return ' '.join(map(id_to_word, ids))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "8198c170-8349-4f9b-a79a-519a63ccaa61",
      "metadata": {
        "id": "8198c170-8349-4f9b-a79a-519a63ccaa61"
      },
      "source": [
        "# Part 1: Predict relationships among words"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a289a5a-a2ba-46ff-a97b-f24948fe2bc6",
      "metadata": {
        "id": "6a289a5a-a2ba-46ff-a97b-f24948fe2bc6"
      },
      "source": [
        "Now you will write a function that will use the word embeddings to predict relationships among words.\n",
        "* The function will take as input three words.\n",
        "* The first two are related to each other.\n",
        "* It will predict a 4th word which is related to the third word in a similar manner as the two first words are related to each other.\n",
        "* As an example, \"Athens is to Greece as Bangkok is to ______\"?\n",
        "* You will write a program that is capable of finding the fourth word.\n",
        "* We will give you a hint to show you how to compute this.\n",
        "\n",
        "A similar analogy would be the following:\n",
        "\n",
        "<img src = 'https://msadraeij.ir:2083/public_assets/vectors.jpg' width=\"width\" height=\"height\" style=\"width:467px;height:200px;\"/>\n",
        "\n",
        "You will implement a function that can tell you the capital of a country.\n",
        "You should use the same methodology shown in the figure above. To do this,\n",
        "compute you'll first compute cosine similarity metric or the Euclidean distance."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6c25731-2a8e-4b58-b577-07755848df27",
      "metadata": {
        "id": "b6c25731-2a8e-4b58-b577-07755848df27"
      },
      "source": [
        "### Cosine Similarity\n",
        "\n",
        "The cosine similarity function is:\n",
        "\n",
        "$$\\cos (\\theta)=\\frac{\\mathbf{A} \\cdot \\mathbf{B}}{\\|\\mathbf{A}\\|\\|\\mathbf{B}\\|}=\\frac{\\sum_{i=1}^{n} A_{i} B_{i}}{\\sqrt{\\sum_{i=1}^{n} A_{i}^{2}} \\sqrt{\\sum_{i=1}^{n} B_{i}^{2}}}\\tag{1}$$\n",
        "\n",
        "$A$ and $B$ represent the word vectors and $A_i$ or $B_i$ represent index i of that vector.\n",
        "& Note that if A and B are identical, you will get $cos(\\theta) = 1$.\n",
        "* Otherwise, if they are the total opposite, meaning, $A= -B$, then you would get $cos(\\theta) = -1$.\n",
        "* If you get $cos(\\theta) =0$, that means that they are orthogonal (or perpendicular).\n",
        "* Numbers between 0 and 1 indicate a similarity score.\n",
        "* Numbers between -1-0 indicate a dissimilarity score.\n",
        "\n",
        "**Instructions**: Implement a function that takes in two word vectors and computes the cosine distance.\n",
        "\n",
        "**Hint**: You can use numpy functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ccf39e2e-4f49-491c-9f46-d10309106b93",
      "metadata": {
        "id": "ccf39e2e-4f49-491c-9f46-d10309106b93"
      },
      "outputs": [],
      "source": [
        "def cosine_similarity(A, B):\n",
        "    A = A.flatten()\n",
        "    B = B.flatten()\n",
        "    #____________YOUR CODE GOES HERE____________\n",
        "    #REPLACE INSTANCES OF 'None' with your code\n",
        "    dot = np.dot(A,B)\n",
        "    norma = np.linalg.norm(A)\n",
        "    normb = np.linalg.norm(B)\n",
        "    cos = dot/(norma*normb)\n",
        "    #______________END BLOCK CODE_______________\n",
        "    return cos"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33ab06d2-9a2c-4ade-b2e3-0439f7f55c9c",
      "metadata": {
        "id": "33ab06d2-9a2c-4ade-b2e3-0439f7f55c9c"
      },
      "source": [
        "### Euclidean distance\n",
        "\n",
        "You will now implement a function that computes the similarity between two vectors using the Euclidean distance.\n",
        "Euclidean distance is defined as:\n",
        "\n",
        "$$ \\begin{aligned} d(\\mathbf{A}, \\mathbf{B})=d(\\mathbf{B}, \\mathbf{A}) &=\\sqrt{\\left(A_{1}-B_{1}\\right)^{2}+\\left(A_{2}-B_{2}\\right)^{2}+\\cdots+\\left(A_{n}-B_{n}\\right)^{2}} \\\\ &=\\sqrt{\\sum_{i=1}^{n}\\left(A_{i}-B_{i}\\right)^{2}} \\end{aligned}$$\n",
        "\n",
        "* $n$ is the number of elements in the vector\n",
        "* $A$ and $B$ are the corresponding word vectors. \n",
        "* The more similar the words, the more likely the Euclidean distance will be close to 0. \n",
        "\n",
        "**Instructions**: Write a function that computes the Euclidean distance between two vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a251e69e-c488-4c6c-9126-c8742841673c",
      "metadata": {
        "id": "a251e69e-c488-4c6c-9126-c8742841673c"
      },
      "outputs": [],
      "source": [
        "def euclidean(A, B):\n",
        "    d = math.dist(A,B)\n",
        "    return d"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f013dc7-8d8a-41e7-8b97-0ce58357974d",
      "metadata": {
        "id": "2f013dc7-8d8a-41e7-8b97-0ce58357974d"
      },
      "source": [
        "### Let's find out queen\n",
        "\n",
        "We are going to find queen using `Cosine Similarity`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bce3ff9-03a4-43c3-9f2b-1c4e0e41c5f1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bce3ff9-03a4-43c3-9f2b-1c4e0e41c5f1",
        "outputId": "a1c30bc5-20ff-4bbc-c9db-e5221810d8e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('king', 0.8065858072579271), ('queen', 0.6896163179535121), ('monarch', 0.5575490920610626), ('throne', 0.5565374575062252), ('princess', 0.5518684267067457)]\n"
          ]
        }
      ],
      "source": [
        "king_emb = emb_matrix[word_to_ids('king')]\n",
        "man_emb = emb_matrix[word_to_ids('man')]\n",
        "woman_emb = emb_matrix[word_to_ids('woman')]\n",
        "\n",
        "query = king_emb - man_emb + woman_emb\n",
        "word_scores = list(map(lambda x: (x[0], cosine_similarity(query, x[1])), zip(word_list[:-1], emb_matrix)))\n",
        "sorted_word_scores = sorted(word_scores, key=lambda x: x[1], reverse=True)\n",
        "top5 = sorted_word_scores[:5]\n",
        "print(top5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f82f0a18-f2e7-4d73-984f-da7f03e2be8d",
      "metadata": {
        "id": "f82f0a18-f2e7-4d73-984f-da7f03e2be8d"
      },
      "source": [
        "**It's Great**\n",
        "\n",
        "Queen is in top5"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d51dd2ba-1316-4836-9a68-5c2af5b82c72",
      "metadata": {
        "id": "d51dd2ba-1316-4836-9a68-5c2af5b82c72"
      },
      "source": [
        "### Finding the country of each capital\n",
        "\n",
        "Now, you  will use the previous functions to compute similarities between vectors,\n",
        "and use these to find the capital cities of countries. You will write a function that\n",
        "takes in three words, and the embeddings dictionary. Your task is to find the\n",
        "capital cities. For example, given the following words: \n",
        "\n",
        "- 1: Athens 2: Greece 3: Baghdad,\n",
        "\n",
        "your task is to predict the country 4: Iraq.\n",
        "\n",
        "**Instructions**: \n",
        "\n",
        "1. To predict the capital you might want to look at the *King - Man + Woman = Queen* example above, and implement that scheme into a mathematical function, using the word embeddings and a similarity function.\n",
        "\n",
        "2. Iterate over the embeddings dictionary and compute the cosine similarity score between your vector and the current word embedding.\n",
        "\n",
        "3. You should add a check to make sure that the word you return is not any of the words that you fed into your function. Return the one with the highest score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "8fcbf002-6d40-43d4-945d-08f0bbeccff0",
      "metadata": {
        "id": "8fcbf002-6d40-43d4-945d-08f0bbeccff0"
      },
      "outputs": [],
      "source": [
        "def get_top5_country(city1, country1, city2):\n",
        "    city1_emb = emb_matrix[word_to_ids(str(city1))]\n",
        "    country1_emb = emb_matrix[word_to_ids(str(country1))]\n",
        "    city2_emb = emb_matrix[word_to_ids(str(city2))]\n",
        "    query = country1_emb - city1_emb + city2_emb\n",
        "    word_scores = list(map(lambda x: (x[0], cosine_similarity(query, x[1])), zip(word_list[:-1], emb_matrix)))\n",
        "    sorted_word_scores = sorted(word_scores, key=lambda x: x[1], reverse=True)\n",
        "    top5=[]; i=1;\n",
        "    while len(top5)<5:\n",
        "        w=sorted_word_scores[i]\n",
        "        if w not in [city1, country1, city2]:\n",
        "            top5.append(w)\n",
        "        i+=1\n",
        "    print(top5)\n",
        "    return top5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4a91851-93db-4b1b-a2da-8f4e30cda967",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4a91851-93db-4b1b-a2da-8f4e30cda967",
        "outputId": "28ef29c0-5f27-413e-fd2e-520206e5ffa0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('iran', 0.7953298646285731), ('iranian', 0.6305805062022181), ('syria', 0.5452216125676077), ('ahmadinejad', 0.5421629020046366), ('iranians', 0.5278357585912685)]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[('iran', 0.7953298646285731),\n",
              " ('iranian', 0.6305805062022181),\n",
              " ('syria', 0.5452216125676077),\n",
              " ('ahmadinejad', 0.5421629020046366),\n",
              " ('iranians', 0.5278357585912685)]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_top5_country('athens', 'greece', 'tehran')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55b277ae-bb79-4500-baff-144acc57e422",
      "metadata": {
        "id": "55b277ae-bb79-4500-baff-144acc57e422"
      },
      "source": [
        "**It's Great**\n",
        "\n",
        "Iran is in top5"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "d7845f1f-1670-4a13-a00b-ab4e5fc41597",
      "metadata": {
        "id": "d7845f1f-1670-4a13-a00b-ab4e5fc41597"
      },
      "source": [
        "# Part 2: Plotting the vectors using PCA"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25089b5c-b51e-4c72-ada9-a2fb9bc78e57",
      "metadata": {
        "id": "25089b5c-b51e-4c72-ada9-a2fb9bc78e57"
      },
      "source": [
        "Now you will explore the distance between word vectors after reducing their dimension.\n",
        "The technique we will employ is known as\n",
        "[*principal component analysis* (PCA)](https://en.wikipedia.org/wiki/Principal_component_analysis).\n",
        "As we saw, we are working in a 300-dimensional space in this case.\n",
        "Although from a computational perspective we were able to perform a good job,\n",
        "it is impossible to visualize results in such high dimensional spaces.\n",
        "\n",
        "You can think of PCA as a method that projects our vectors in a space of reduced\n",
        "dimension, while keeping the maximum information about the original vectors in\n",
        "their reduced counterparts. In this case, by *maximum infomation* we mean that the\n",
        "Euclidean distance between the original vectors and their projected siblings is\n",
        "minimal. Hence vectors that were originally close in the embeddings dictionary,\n",
        "will produce lower dimensional vectors that are still close to each other.\n",
        "\n",
        "You will see that when you map out the words, similar words will be clustered\n",
        "next to each other. For example, the words 'sad', 'happy', 'joyful' all describe\n",
        "emotion and are supposed to be near each other when plotted.\n",
        "The words: 'oil', 'gas', and 'petroleum' all describe natural resources.\n",
        "Words like 'city', 'village', 'town' could be seen as synonyms and describe a\n",
        "similar thing.\n",
        "\n",
        "Before plotting the words, you need to first be able to reduce each word vector\n",
        "with PCA into 2 dimensions and then plot it. The steps to compute PCA are as follows:\n",
        "\n",
        "1. Mean normalize the data\n",
        "2. Compute the covariance matrix of your data ($\\Sigma$). \n",
        "3. Compute the eigenvectors and the eigenvalues of your covariance matrix\n",
        "4. Multiply the first K eigenvectors by your normalized data. The transformation should look something as follows:\n",
        "\n",
        "<img src = 'https://msadraeij.ir:2083/public_assets/word_embf.jpg' width=\"width\" height=\"height\" style=\"width:800px;height:200px;\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11ea4190-7b4f-44b7-a870-8da4b2afe78f",
      "metadata": {
        "id": "11ea4190-7b4f-44b7-a870-8da4b2afe78f"
      },
      "source": [
        "**Instructions**: \n",
        "\n",
        "You will write a program that takes in a data set where each row corresponds to a word vector. \n",
        "* The word vectors are of dimension 300. \n",
        "* Use PCA to change the 300 dimensions to `n_components` dimensions. \n",
        "* The new matrix should be of dimension `m, n_componentns`. \n",
        "\n",
        "* First de-mean the data\n",
        "* Get the eigenvalues using `linalg.eigh`.  Use `eigh` rather than `eig` since R is symmetric.  The performance gain when using `eigh` instead of `eig` is substantial.\n",
        "* Sort the eigenvectors and eigenvalues by decreasing order of the eigenvalues.\n",
        "* Get a subset of the eigenvectors (choose how many principle components you want to use using `n_components`).\n",
        "* Return the new transformation of the data by multiplying the eigenvectors with the original data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56f9ee08-af39-4be7-8ee7-19fec2cae5d0",
      "metadata": {
        "id": "56f9ee08-af39-4be7-8ee7-19fec2cae5d0"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from numpy import mean\n",
        "from numpy import cov\n",
        "from numpy import linalg\n",
        "from numpy.linalg import eig\n",
        "def compute_pca(X, n_components=2):\n",
        "\n",
        "    M = mean(X.T, axis=1)\n",
        "# center columns by subtracting column means\n",
        "    C = X - M\n",
        "# calculate covariance matrix of centered matrix\n",
        "    V = cov(C.T)\n",
        "# eigendecomposition of covariance matrix\n",
        "    values, vectors = eig(V)\n",
        "# project data\n",
        "    X_reduced = vectors.T.dot(C.T)\n",
        "    return X_reduced"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8671dc5-a3ee-4d33-bf6f-16797010caf6",
      "metadata": {
        "id": "c8671dc5-a3ee-4d33-bf6f-16797010caf6"
      },
      "source": [
        "### Plot some words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "416eacd4-9748-4f26-9a10-ba92d2350251",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 583
        },
        "id": "416eacd4-9748-4f26-9a10-ba92d2350251",
        "outputId": "5d75dbea-aa07-4aa9-a223-de279b369b93"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/matplotlib/collections.py:153: ComplexWarning: Casting complex values to real discards the imaginary part\n",
            "  offsets = np.asanyarray(offsets, float)\n",
            "/usr/local/lib/python3.8/dist-packages/matplotlib/text.py:1769: ComplexWarning: Casting complex values to real discards the imaginary part\n",
            "  x = float(self.convert_xunits(x))\n",
            "/usr/local/lib/python3.8/dist-packages/matplotlib/text.py:1771: ComplexWarning: Casting complex values to real discards the imaginary part\n",
            "  y = float(self.convert_yunits(y))\n",
            "/usr/local/lib/python3.8/dist-packages/matplotlib/text.py:828: ComplexWarning: Casting complex values to real discards the imaginary part\n",
            "  x = float(self.convert_xunits(self._x))\n",
            "/usr/local/lib/python3.8/dist-packages/matplotlib/text.py:829: ComplexWarning: Casting complex values to real discards the imaginary part\n",
            "  y = float(self.convert_yunits(self._y))\n",
            "/usr/local/lib/python3.8/dist-packages/matplotlib/text.py:690: ComplexWarning: Casting complex values to real discards the imaginary part\n",
            "  posx = float(textobj.convert_xunits(textobj._x))\n",
            "/usr/local/lib/python3.8/dist-packages/matplotlib/text.py:691: ComplexWarning: Casting complex values to real discards the imaginary part\n",
            "  posy = float(textobj.convert_yunits(textobj._y))\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "selected_words = ['oil', 'gas', 'happy', 'sad', 'city', 'town', 'village', 'country', 'continent', 'petroleum', 'joyful']\n",
        "\n",
        "selected_words_emb = np.vstack([emb_matrix[word_to_ids(word)] for word in selected_words])\n",
        "\n",
        "result = compute_pca(selected_words_emb, 2)\n",
        "plt.figure(figsize=[10,5])\n",
        "plt.scatter(result[:, 0], result[:, 1])\n",
        "for i, word in enumerate(selected_words):\n",
        "    plt.annotate(word, xy=(result[i, 0] - 0.05, result[i, 1] + 0.1))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9ea1201-fd2d-4439-8e70-050dc8bb03d2",
      "metadata": {
        "id": "f9ea1201-fd2d-4439-8e70-050dc8bb03d2"
      },
      "source": [
        "# Part 3: Classification using a simple bag of words (10% grade)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3qDML60LE07g",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qDML60LE07g",
        "outputId": "020bafff-b470-4ce7-9566-1eaaa14a3bd1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[13075, 197, 32, 81, 188]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# test:\n",
        "tx='hello how are you ?'\n",
        "len(sentence_to_ids('s'))\n",
        "sentence_to_ids(tx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "1fc87523-1e14-4747-abdc-9f827c60150e",
      "metadata": {
        "id": "1fc87523-1e14-4747-abdc-9f827c60150e"
      },
      "outputs": [],
      "source": [
        "def sentence_to_emb(sentence: str):\n",
        "    return_value = np.zeros((EMB_SIZE,))\n",
        "    token_ids = sentence_to_ids(sentence) # returns an id for each token\n",
        "    for token_id in token_ids: # produce an average embeding for the sentence\n",
        "        return_value += emb_matrix[token_id]\n",
        "\n",
        "    return_value = return_value / len(token_ids)\n",
        "    return return_value"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93d63627-0fbf-4012-be7e-07302a596702",
      "metadata": {
        "id": "93d63627-0fbf-4012-be7e-07302a596702"
      },
      "source": [
        "### Define our simple model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbde2f88-0a2e-43bf-a8a2-e21bd3c22669",
      "metadata": {
        "id": "dbde2f88-0a2e-43bf-a8a2-e21bd3c22669"
      },
      "outputs": [],
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Linear(EMB_SIZE, EMB_SIZE),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(EMB_SIZE, EMB_SIZE),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(EMB_SIZE, EMB_SIZE),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(EMB_SIZE, EMB_SIZE),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(EMB_SIZE, 2)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d23a82be-2560-4dd7-a574-0f5fdcd93105",
      "metadata": {
        "id": "d23a82be-2560-4dd7-a574-0f5fdcd93105"
      },
      "source": [
        "### Define our dataset and dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "799a7e9d-9216-48fe-b3ff-dda296796fc9",
      "metadata": {
        "id": "799a7e9d-9216-48fe-b3ff-dda296796fc9"
      },
      "outputs": [],
      "source": [
        "class Method1Dataset(Dataset):\n",
        "    def __init__(self, datadict):\n",
        "        self.data = [(sentence_to_emb(sentence), semantic)for sentence, semantic in datadict]\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Cwi8_kaJG54V",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cwi8_kaJG54V",
        "outputId": "8822e2c6-69e1-4b81-e2ba-c28c9216250f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8000"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_dataset['train'][0]\n",
        "len(all_dataset['train'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c908988-8291-4b67-a7bb-499065bf590f",
      "metadata": {
        "id": "2c908988-8291-4b67-a7bb-499065bf590f"
      },
      "outputs": [],
      "source": [
        "train_dataset = Method1Dataset(all_dataset['train'])\n",
        "eval_dataset = Method1Dataset(all_dataset['eval'])\n",
        "test_dataset = Method1Dataset(all_dataset['test'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a215fcf5-ff3e-4fe6-9029-f365cd5e286e",
      "metadata": {
        "id": "a215fcf5-ff3e-4fe6-9029-f365cd5e286e"
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(train_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True)\n",
        "eval_dataloader = DataLoader(eval_dataset, batch_size=TEST_EVAL_BATCH_SIZE, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=TEST_EVAL_BATCH_SIZE, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7647d0d4-081e-4829-a606-dd9d37e1a3a5",
      "metadata": {
        "id": "7647d0d4-081e-4829-a606-dd9d37e1a3a5"
      },
      "source": [
        "### Define our training routine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b189554c-b897-4fef-9bc5-c22aa2e82dd9",
      "metadata": {
        "id": "b189554c-b897-4fef-9bc5-c22aa2e82dd9"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f5a7eb0-a8ba-44e4-84db-ae979b4bbd9a",
      "metadata": {
        "id": "3f5a7eb0-a8ba-44e4-84db-ae979b4bbd9a"
      },
      "outputs": [],
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for i, batch in enumerate(iterator):\n",
        "        x, trg = batch\n",
        "        optimizer.zero_grad()\n",
        "        output = model(x.float())\n",
        "        \n",
        "        loss = criterion(output, trg)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "    \n",
        "    return epoch_loss / len(iterator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "558bd8c4-ee8c-49fd-8ec0-07c422147fe4",
      "metadata": {
        "id": "558bd8c4-ee8c-49fd-8ec0-07c422147fe4"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for i, batch in enumerate(iterator):\n",
        "            x, trg = batch\n",
        "            output = model(x.float())\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f0a8e94-db8b-4370-9df0-f2cf5b205027",
      "metadata": {
        "id": "4f0a8e94-db8b-4370-9df0-f2cf5b205027"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa84453b-e125-4fe6-bd3e-1cdf35e66206",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aa84453b-e125-4fe6-bd3e-1cdf35e66206",
        "outputId": "44f9bdf6-43ec-40da-db9b-9721775d1e9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 01\n",
            "\tTrain Loss: 0.626\n",
            "\t Val. Loss: 0.534\n",
            "Epoch: 02\n",
            "\tTrain Loss: 0.502\n",
            "\t Val. Loss: 0.513\n",
            "Epoch: 03\n",
            "\tTrain Loss: 0.487\n",
            "\t Val. Loss: 0.497\n",
            "Epoch: 04\n",
            "\tTrain Loss: 0.478\n",
            "\t Val. Loss: 0.486\n",
            "Epoch: 05\n",
            "\tTrain Loss: 0.469\n",
            "\t Val. Loss: 0.487\n",
            "Epoch: 06\n",
            "\tTrain Loss: 0.462\n",
            "\t Val. Loss: 0.490\n",
            "Epoch: 07\n",
            "\tTrain Loss: 0.452\n",
            "\t Val. Loss: 0.486\n",
            "Epoch: 08\n",
            "\tTrain Loss: 0.443\n",
            "\t Val. Loss: 0.483\n",
            "Epoch: 09\n",
            "\tTrain Loss: 0.428\n",
            "\t Val. Loss: 0.477\n",
            "Epoch: 10\n",
            "\tTrain Loss: 0.414\n",
            "\t Val. Loss: 0.487\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(10):\n",
        "    train_loss = train(model, train_dataloader, optimizer, criterion)\n",
        "    valid_loss = evaluate(model, eval_dataloader, criterion)\n",
        "    print(f'Epoch: {epoch+1:02}')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26fd26e2-ba81-4b48-9915-ebfe69aa7c20",
      "metadata": {
        "id": "26fd26e2-ba81-4b48-9915-ebfe69aa7c20"
      },
      "source": [
        "### Check the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57eddc71-714b-42d6-8a67-2bc98c882046",
      "metadata": {
        "id": "57eddc71-714b-42d6-8a67-2bc98c882046"
      },
      "outputs": [],
      "source": [
        "def get_all_targets_and_predicted(model, iterator):\n",
        "    all_trg = []\n",
        "    all_prd = []\n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "            x, trg = batch\n",
        "            output = model(x.float())\n",
        "            prd = output.argmax(1).tolist()\n",
        "            \n",
        "            all_trg += trg\n",
        "            all_prd += prd\n",
        "    return all_trg, all_prd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1ed020c-f21d-4d6f-b84b-4f2db54cbf7f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1ed020c-f21d-4d6f-b84b-4f2db54cbf7f",
        "outputId": "c9d3f1b3-bc50-497e-ec8c-e059a0b35893"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "__________________TRAIN DATASET__________________\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.90      0.83      4000\n",
            "           1       0.88      0.73      0.80      4000\n",
            "\n",
            "    accuracy                           0.82      8000\n",
            "   macro avg       0.83      0.82      0.81      8000\n",
            "weighted avg       0.83      0.82      0.81      8000\n",
            "\n",
            "__________________EVAL DATASET__________________\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.84      0.78      1000\n",
            "           1       0.81      0.68      0.74      1000\n",
            "\n",
            "    accuracy                           0.76      2000\n",
            "   macro avg       0.76      0.76      0.76      2000\n",
            "weighted avg       0.76      0.76      0.76      2000\n",
            "\n",
            "__________________TEST DATASET__________________\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.87      0.78       331\n",
            "           1       0.83      0.64      0.72       331\n",
            "\n",
            "    accuracy                           0.76       662\n",
            "   macro avg       0.77      0.76      0.75       662\n",
            "weighted avg       0.77      0.76      0.75       662\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print('__________________TRAIN DATASET__________________')\n",
        "trg, prd = get_all_targets_and_predicted(model, train_dataloader)\n",
        "print(classification_report(trg, prd))\n",
        "print('__________________EVAL DATASET__________________')\n",
        "trg, prd = get_all_targets_and_predicted(model, eval_dataloader)\n",
        "print(classification_report(trg, prd))\n",
        "print('__________________TEST DATASET__________________')\n",
        "trg, prd = get_all_targets_and_predicted(model, test_dataloader)\n",
        "print(classification_report(trg, prd))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "134984dd-592a-4f74-84a7-bd11b16a203a",
      "metadata": {
        "id": "134984dd-592a-4f74-84a7-bd11b16a203a"
      },
      "source": [
        "# Part 4: Classification using an LSTM classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15c8f6ae-33f0-40c9-b22c-9ffbac4413ee",
      "metadata": {
        "id": "15c8f6ae-33f0-40c9-b22c-9ffbac4413ee"
      },
      "source": [
        "Use pytorch to implement an lstm model classifier. You can use any hyperparameters you want. You must report `classification_report` like previous example for all datasets. Remember your embeding layer initial value must be `emb_matrix`.\n",
        "\n",
        "You must train the model two times.\n",
        "First time freeze the embeding layer and second time fine-tune it end2end.\n",
        "After that compare these two results and explatin the trade-off between freezing or fine-tuning the embedding layer.\n",
        "You can read more about this in <a href=\"https://web.stanford.edu/class/cs224n/slides/cs224n-2019-lecture04-backprop.pdf\">this link</a>.\n",
        "\n",
        "Good Luck"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "WhubYoODFykI",
      "metadata": {
        "id": "WhubYoODFykI"
      },
      "outputs": [],
      "source": [
        "del word_list, emb_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "8xyFHp5h_SAe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xyFHp5h_SAe",
        "outputId": "822686f8-edf2-4f2f-8d89-e348d2f324f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "Akm-rc0ZU4lp",
      "metadata": {
        "id": "Akm-rc0ZU4lp"
      },
      "outputs": [],
      "source": [
        "def txt2ID(sentence , length=64):\n",
        "  ids = sentence_to_ids(sentence)\n",
        "  padding = [word_to_ids(\"<PAD>\")[0] for _ in range(length - len(ids))]\n",
        "  \n",
        "  return ids + padding\n",
        "# txt2ID('hello how are you', 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "HAMdqsrIXasH",
      "metadata": {
        "id": "HAMdqsrIXasH"
      },
      "outputs": [],
      "source": [
        "class Method2Dataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data=data\n",
        "        self.ID_txt = torch.tensor([txt2ID(data[i][0]) for i in range(len(data))])\n",
        "        self.label = [data[i][1] for i in range(len(data))]\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    def give_txt(self,idx):\n",
        "        return self.data[idx][0]\n",
        "    def __getitem__(self, idx):\n",
        "        return (self.ID_txt[idx],self.label[idx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "C0931zHBZT_d",
      "metadata": {
        "id": "C0931zHBZT_d"
      },
      "outputs": [],
      "source": [
        "# train_dataset = Method2Dataset(all_dataset['train'])\n",
        "# train_dataloader = DataLoader(train_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# for i, batch in enumerate(train_dataloader):\n",
        "#     x, trg = batch\n",
        "#     break\n",
        "#     # output = model(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "Kvd3LvwvobzI",
      "metadata": {
        "id": "Kvd3LvwvobzI"
      },
      "outputs": [],
      "source": [
        "# defining Datasets\n",
        "train_dataset = Method2Dataset(all_dataset['train'])\n",
        "eval_dataset = Method2Dataset(all_dataset['eval'])\n",
        "test_ddataset = Method2Dataset(all_dataset['test'])\n",
        "del all_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "JoGEBxKkVwIA",
      "metadata": {
        "id": "JoGEBxKkVwIA"
      },
      "outputs": [],
      "source": [
        "# defining DataLoaders\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True)\n",
        "eval_dataloader = DataLoader(eval_dataset, batch_size=TEST_EVAL_BATCH_SIZE, shuffle=True)\n",
        "test_dataloader = DataLoader(test_ddataset, batch_size=TEST_EVAL_BATCH_SIZE, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "kMewuKVMGmpI",
      "metadata": {
        "id": "kMewuKVMGmpI"
      },
      "outputs": [],
      "source": [
        "del train_dataset, eval_dataset, test_ddataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68711d19",
      "metadata": {},
      "source": [
        "implementing the training procedure for one batch or one data gives a good insight."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 200,
      "id": "f4GlrFcSpi_d",
      "metadata": {
        "id": "f4GlrFcSpi_d"
      },
      "outputs": [],
      "source": [
        "# # For one data \n",
        "# num_embeddings, emb_size = emb_matrix.shape\n",
        "# embedding = nn.Embedding(num_embeddings, emb_size)\n",
        "# embedding.weight.data.copy_(torch.from_numpy(emb_matrix))\n",
        "# lstm = nn.LSTM(emb_size, hidden_size=64, num_layers=1, batch_first=True)\n",
        "# fc = nn.Linear(64, 2)\n",
        "# x_in=train_dataset.__getitem__(1)[0]\n",
        "# emb_in = embedding(x_in)\n",
        "# x, (h_n, c_n) = lstm(emb_in)\n",
        "# # x[-1]==h_n\n",
        "# x = fc(x[-1])\n",
        "# print(x.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "wx35Y1YAU0m7",
      "metadata": {
        "id": "wx35Y1YAU0m7"
      },
      "outputs": [],
      "source": [
        "#____________YOUR CODE GOES HERE____________\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "class LSTMClassifier(nn.Module):\n",
        "    def __init__(self, emb_matrix, freeze_embedding):\n",
        "        super().__init__()\n",
        "        num_embeddings, emb_size = emb_matrix.shape\n",
        "        self.embedding = nn.Embedding(num_embeddings, emb_size)\n",
        "        self.embedding.weight.data.copy_(torch.from_numpy(emb_matrix))\n",
        "        \n",
        "        if freeze_embedding:\n",
        "            self.embedding.weight.requires_grad = False\n",
        "        \n",
        "        self.lstm = nn.LSTM(emb_size, hidden_size=64, num_layers=1, batch_first=True)\n",
        "        self.fc = nn.Linear(64, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.long()\n",
        "        embeded = self.embedding(x)\n",
        "        out, (h_n, c_n) = self.lstm(embeded)\n",
        "        x = self.fc(out[:,-1,:])\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "LuPb_2k3_rbY",
      "metadata": {
        "id": "LuPb_2k3_rbY"
      },
      "outputs": [],
      "source": [
        "model = LSTMClassifier(emb_matrix,freeze_embedding=True).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "5hWEQLzmyeEE",
      "metadata": {
        "id": "5hWEQLzmyeEE"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "PuVRby_IuNaP",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PuVRby_IuNaP",
        "outputId": "5c567cfa-ad4d-400c-e126-7f33bc9e62c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([32, 64])\n",
            "torch.Size([32, 64, 300])\n",
            "torch.Size([32, 64, 30])\n",
            "torch.Size([1, 32, 30])\n",
            "torch.Size([32, 1])\n"
          ]
        }
      ],
      "source": [
        "# # For one batch \n",
        "# num_embeddings, emb_size = emb_matrix.shape\n",
        "# embedding = nn.Embedding(num_embeddings, emb_size)\n",
        "# embedding.weight.data.copy_(torch.from_numpy(emb_matrix))\n",
        "# lstm = nn.LSTM(emb_size, hidden_size=30, num_layers=1, batch_first=True)\n",
        "# fc = nn.Linear(30, 1)\n",
        "# print(data.size())\n",
        "# embeded = embedding(data)\n",
        "# print(embeded.size())\n",
        "# x, (h_n, c_n) = lstm(embeded)\n",
        "# print(x.size())\n",
        "# print(h_n.size())\n",
        "# x = fc(x[:,-1,:])\n",
        "# print(x.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "vl_Tq3Ap9JBo",
      "metadata": {
        "id": "vl_Tq3Ap9JBo"
      },
      "outputs": [],
      "source": [
        "######################   Training   ########################\n",
        "from tqdm import tqdm\n",
        "# train the model for a specified number of epochs\n",
        "def trainer(model,num_epochs = 3):\n",
        "    model=model.to(device)\n",
        "    for epoch in range(num_epochs):\n",
        "        # set the model to training mode\n",
        "        model.train()\n",
        "\n",
        "        # use tqdm to display a progress bar during training\n",
        "        with tqdm(train_dataloader) as pbar:\n",
        "            for text, label in pbar:\n",
        "                label=label.to(device)\n",
        "                text=text.to(device)\n",
        "                # make predictions on the batch of data\n",
        "                out_put = model(text)\n",
        "\n",
        "                # calculate the loss\n",
        "                loss = criterion(out_put.squeeze(), label.float())\n",
        "\n",
        "                # reset the gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # backpropagate the loss\n",
        "                loss.backward()\n",
        "\n",
        "                # update the model's parameters\n",
        "                optimizer.step()\n",
        "\n",
        "                # update the progress bar\n",
        "                pbar.set_description(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}')\n",
        "\n",
        "        # set the model to evaluation mode\n",
        "        model.eval()\n",
        "        loss_val_sum=0\n",
        "        # use the model to make predictions on the validation data\n",
        "        with torch.no_grad():\n",
        "            for text, label in eval_dataloader:\n",
        "                label=label.to(device)\n",
        "                text=text.to(device)\n",
        "                predictions_val = model(text)\n",
        "                # calculate the loss of the model on the validation data\n",
        "                loss_val = criterion(predictions_val.squeeze(), label.float())\n",
        "                loss_val_sum=loss_val_sum+loss_val\n",
        "            print(f'TestLoss: {loss_val_sum/len(eval_dataloader):.4f}')\n",
        "############################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "oZJ6la1mHVHW",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZJ6la1mHVHW",
        "outputId": "ac15b132-25df-4c6e-f624-57d7ec58ac28"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/5, Loss: 45.0546: 100%|██████████| 250/250 [00:04<00:00, 51.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TestLoss: 54.9682\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/5, Loss: 65.8490: 100%|██████████| 250/250 [00:04<00:00, 53.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TestLoss: 54.9129\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/5, Loss: 48.5204: 100%|██████████| 250/250 [00:05<00:00, 47.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TestLoss: 54.9350\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/5, Loss: 55.4518: 100%|██████████| 250/250 [00:06<00:00, 38.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TestLoss: 54.9028\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/5, Loss: 69.3125: 100%|██████████| 250/250 [00:03<00:00, 76.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TestLoss: 54.9017\n"
          ]
        }
      ],
      "source": [
        "trainer(model,5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "JOgnOh1hFh2B",
      "metadata": {
        "id": "JOgnOh1hFh2B"
      },
      "outputs": [],
      "source": [
        "model2 = LSTMClassifier(emb_matrix,freeze_embedding=False).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "W8I0JWgMHnim",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8I0JWgMHnim",
        "outputId": "eb88a49f-5c7f-4f4c-d077-897f7f90c0e8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/5, Loss: 62.3832: 100%|██████████| 250/250 [00:09<00:00, 25.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TestLoss: 54.9457\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/5, Loss: 58.9175: 100%|██████████| 250/250 [00:07<00:00, 35.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TestLoss: 54.8797\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/5, Loss: 58.9175: 100%|██████████| 250/250 [00:12<00:00, 19.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TestLoss: 54.9457\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/5, Loss: 72.7804: 100%|██████████| 250/250 [00:07<00:00, 33.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TestLoss: 54.9677\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/5, Loss: 51.9860: 100%|██████████| 250/250 [00:09<00:00, 25.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TestLoss: 54.8797\n"
          ]
        }
      ],
      "source": [
        "trainer(model2,5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "h8LLpyS4H3GP",
      "metadata": {
        "id": "h8LLpyS4H3GP"
      },
      "source": [
        "# Conclusion: \n",
        "main differences between two models:\n",
        "\n",
        "1. Learnability: A learnable embedding matrix can capture the meaning of the words more accurately by adapting to the specific characteristics of the training data, while a constant embedding matrix has fixed values that cannot be adapted to the training data.\n",
        "\n",
        "2. Model capacity: A learnable embedding matrix adds additional parameters to the model, which increases the model's capacity and allows it to learn more complex relationships between the input and output. A constant embedding matrix has fewer parameters, which reduces the model's capacity and limits its ability to learn complex relationships.\n",
        "\n",
        "3. Training time: A learnable embedding matrix requires more time to train, as the model has to optimize the values in the embedding matrix as well as the other parameters of the model. A constant embedding matrix requires less time to train, as the values in the embedding matrix are fixed and do not need to be optimized. This time difference can be clearly observed in the results of the training.\n",
        "\n",
        "4. Model performance: In general, a learnable embedding matrix tends to outperform a constant embedding matrix in NLP text classification tasks, as it can capture the meanings of the words more accurately and learn more complex relationships between the input and output. However, the performance of a learnable embedding matrix may vary depending on the specific characteristics of the training data and the complexity of the task. However in our case due to computational cost restrictions the models are learned for 5 epoches and this point is not clear.\n",
        "\n",
        "In summary, using a learnable embedding matrix or a constant embedding matrix in an LSTM model for NLP text classification can have different effects on the model's learnability, capacity, training time, and performance. You can choose the appropriate approach based on the specific requirements of your task and the resources available."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "8198c170-8349-4f9b-a79a-519a63ccaa61",
        "d7845f1f-1670-4a13-a00b-ab4e5fc41597",
        "f9ea1201-fd2d-4439-8e70-050dc8bb03d2"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9 (tags/v3.9.9:ccb0e6a, Nov 15 2021, 18:08:50) [MSC v.1929 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "7ab1b3b9c0c9f281d6bc953a53ef072fab980f11978a31dd5e3f47f782640e38"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
